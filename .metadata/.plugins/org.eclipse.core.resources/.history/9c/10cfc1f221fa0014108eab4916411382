package ca.effpro.learn.hadoop.mr.format.zip;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Reducer;

import ca.effpro.hadoop.mrbasics.old.KijijiMRCounterEnums;

public class ZipFileEntryToContentReducer extends Reducer<Text, BytesWritable, Text, Text>
{
  private static final Log logger = LogFactory.getLog(ZipFileEntryToContentReducer.class);
  
  private org.apache.hadoop.conf.Configuration conf;
  
  byte[] buffer = null;
  
  public void setup(Reducer<Text, BytesWritable, Text, Text>.Context context) throws IOException, InterruptedException { conf = context.getConfiguration();
    logger.info("Set up invoked ...");
  }
  
  public void reduce(Text key, Iterable<BytesWritable> values, Reducer<Text, BytesWritable, Text, Text>.Context context)
    throws IOException, InterruptedException
  {
    logger.info("reducer invoked ...");
    
   
   for (BytesWritable value : values) {
	  ArrayUtils.add( lstContent.add(value.getBytes());
   }
   
   context.write(key, value);
   
  }
}