package ca.effpro.learn.hadoop.mr.tpt.avro;

import java.io.IOException;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

/**
 * Used for logging file names (in the zip file) entries.
 * 
 * Input Key : filename (from zip file) Input Value : file content Output Key :
 * filename (from zip file) Output Value : file content
 *
 */
public class ZipFileEntriesToContentMapper extends
		Mapper<Text, BytesWritable, Text, Text> {
	private static final Log logger = LogFactory
			.getLog(ZipFileEntriesToAvroMapper.class);

	private Text outKey = new Text();
	private Text outValue = new Text();
	private org.apache.hadoop.conf.Configuration conf;

	private String fromPreviousRow = "";

	public void setup(Mapper<Text, BytesWritable, Text, Text>.Context context)
			throws IOException, InterruptedException {
		conf = context.getConfiguration();
		// logger.info("Set up invoked ...");
	}

	public void map(Text key, BytesWritable value,
			Mapper<Text, BytesWritable, Text, Text>.Context context)
			throws IOException, InterruptedException {

		String row = fromPreviousRow + new String(value.getBytes());
		int idx = row.lastIndexOf('\n');

		fromPreviousRow = row.substring(idx);
		outValue.set(row.substring(0, idx));

		context.write(key, outValue);
	}
}