package ca.effpro.learn.hadoop.mr.tpt.exer1;

import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.util.HashSet;
import java.util.Set;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.util.StringUtils;

import ca.effpro.hadoop.mrbasics.old.SimpleCounterEnums;
import ca.effpro.learn.hadoop.mr.format.zip.ZipFileEntriesToContentMapper;

/**
 * Mapper class to extract information from the toronto parking data set. 
 * The value of the data records are stored in the format as in the below sample : <br>
 *  <br> 
 * 	tag_number_masked,date_of_infraction,infraction_code,infraction_description,set_fine_amount,time_of_infraction,location1,location2,location3,location4,province
 *	***63611,20080101,3,PARK/LEAVE ON PRIVATE PROPERTY,30,,,364 EAST MALL,,,ON
 *	***99026,20080101,9,STOP HWY PROHIBITED TIME/DAY,60,,,80 RICHMOND ST W,,,ON
 * <br>
 * 	
 *  This mapper class extract the following information from the dataset.
 *  <ol> date of infraction (YYYYMM) => will be part of composite key
 *  <ol> infraction code => will be part of composite key
 *  <ol> set fine amount => will be present in value
 *  <ol> province => will be present in value
 *  <ol>
 */
public class YearMonthInfractionMapper extends
Mapper<Text, Text, Text, Text> {

	private static final Log logger = LogFactory
	.getLog(YearMonthInfractionMapper.class);


	
	
	tag_number_masked,date_of_infraction,infraction_code,infraction_description,set_fine_amount,time_of_infraction,location1,location2,location3,location4,province
	***63611,20080101,3,PARK/LEAVE ON PRIVATE PROPERTY,30,,,364 EAST MALL,,,ON
	***99026,20080101,9,STOP HWY PROHIBITED TIME/DAY,60,,,80 RICHMOND ST W,,,ON

	private final static IntWritable one = new IntWritable(1);
	private Text word = new Text();

	private boolean caseSensitive;
	private Set<String> patternsToSkip = new HashSet<String>();

	private Configuration conf;
	private BufferedReader fis;

	@Override
	public void setup(Context context) throws IOException, InterruptedException {
		conf = context.getConfiguration();
		logger.info("Set up invoked ...");
		/*
		//caseSensitive = conf.getBoolean("wordcount.case.sensitive", true);
		//if (conf.getBoolean("wordcount.skip.patterns", true)) {
			URI[] patternsURIs = Job.getInstance(conf).getCacheFiles();
			for (URI patternsURI : patternsURIs) {
				Path patternsPath = new Path(patternsURI.getPath());
				String patternsFileName = patternsPath.getName().toString();
				parseSkipFile(patternsFileName);
			}
		}
		*/
	}

	private void parseSkipFile(String fileName) {
		try {
			fis = new BufferedReader(new FileReader(fileName));
			String pattern = null;
			while ((pattern = fis.readLine()) != null) {
				patternsToSkip.add(pattern);
			}
		} catch (IOException ioe) {
			System.err
					.println("Caught exception while parsing the cached file '"
							+ StringUtils.stringifyException(ioe));
		}
	}

	@Override
	public void map(LongWritable key, Text value, Context context)
			throws IOException, InterruptedException {
		
		logger.info("map invoked ...");
		
		context.write(new Text("M"), one);
		
		Counter counter = context.getCounter(SimpleCounterEnums.class.getName(),
				SimpleCounterEnums.INPUT_WORDS.toString());
			counter.increment(1);
		
	}
}
