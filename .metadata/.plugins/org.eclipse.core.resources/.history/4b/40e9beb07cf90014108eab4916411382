package ca.effpro.learn.hadoop.mr.format.zip;

import java.io.ByteArrayOutputStream;
import java.io.EOFException;
import java.io.IOException;
import java.util.zip.ZipEntry;
import java.util.zip.ZipException;
import java.util.zip.ZipInputStream;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;

/**
 * This RecordReader implementation extracts individual files from a ZIP file
 * and hands them over to the Mapper. The "key" is the decompressed file name,
 * the "value" is the file contents.
 * 
 * Copied from : https://github.com/cotdp/com-cotdp-hadoop
 */
public class MegaZipFileRecordReader extends ZipFileRecordReader {
	
	private ZipEntry entry = null;

	private boolean moreBytesInFileContent = false;


	@Override
	public boolean nextKeyValue() throws IOException, InterruptedException {

		if (moreBytesInFileContent == false) {
			try {
				entry = zip.getNextEntry();
			} catch (ZipException e) {
				if (ZipFileInputFormat.getLenient() == false)
					throw e;
			}

			// Sanity check
			if (entry == null) {
				isFinished = true;
				return false;
			}

			// Filename
			currentKey = new Text(entry.getName());
		}

		// Read the file contents
		ByteArrayOutputStream bos = new ByteArrayOutputStream();
		byte[] temp = new byte[8192];
		while (true) {
			int bytesRead = 0;
			try {
				bytesRead = zip.read(temp, 0, 8192);
			} catch (EOFException e) {
				if (ZipFileInputFormat.getLenient() == false)
					throw e;
				return false;
			}
			if (bytesRead > 0)
				bos.write(temp, 0, bytesRead);
			else
				break;
		}
		zip.closeEntry();

		// Uncompressed contents
		currentValue = new BytesWritable(bos.toByteArray());
		return true;
	}

	
}