package ca.effpro.learn.hadoop.mr.tpt.exer1;

import java.io.IOException;
import java.util.HashSet;
import java.util.Set;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Reducer;

import ca.effpro.hadoop.mrbasics.old.KijijiMRCounterEnums;
import ca.effpro.hadoop.mrbasics.old.RegionToUniqueLinkReducer;

public class YearlyCollectionOfAmountToInfractionReducer extends
		Reducer<YearMonthToInfractionWritable, Text, Text, IntWritable> {
	private static final Log logger = LogFactory
			.getLog(YearlyCollectionOfAmountToInfractionReducer.class);

	public void reduce(
			YearMonthToInfractionWritable key,
			Iterable<Text> values,
			Reducer<YearMonthToInfractionWritable, Text, Text, IntWritable>.Context context)
			throws IOException, InterruptedException {
		
		logger.info("reducer invoked ...");

		int year = key.getYear().get();
		String infractionCode = key.getInfractionCode().toString();
		Set<String> setOfLinks = new HashSet();

		for (Text value : values) {
			String link = value.toString();

			if (!setOfLinks.contains(link)) {

				setOfLinks.add(link);
				context.write(key, value);

				if (!setOfRegions.contains(key.toString())) {

					setOfRegions.add(key.toString());

					Counter counter = context.getCounter(
							KijijiMRCounterEnums.class.getName(),
							KijijiMRCounterEnums.UNIQUE_REGIONS.toString());
					counter.increment(1L);
				}
			}
		}
	}
}