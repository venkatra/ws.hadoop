package ca.effpro.learn.hadoop.mr.format.zip;

import java.io.IOException;

import org.apache.commons.lang3.ArrayUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class ZipFileEntryToContentReducer extends Reducer<Text, BytesWritable, Text, Text>
{
  private static final Log logger = LogFactory.getLog(ZipFileEntryToContentReducer.class);
  
  private org.apache.hadoop.conf.Configuration conf;
  
 
  
  public void setup(Reducer<Text, BytesWritable, Text, Text>.Context context) throws IOException, InterruptedException { conf = context.getConfiguration();
    logger.info("Set up invoked ...");
  }
  
  public void reduce(Text key, Iterable<BytesWritable> values, Reducer<Text, BytesWritable, Text, Text>.Context context)
    throws IOException, InterruptedException
  {
    logger.info("reducer invoked ...");
    
    int itr = 0;
    byte[] buffer = null;
   for (BytesWritable value : values) {
	   logger.info("ITR count : " + (itr++));
	   buffer = ArrayUtils.addAll(buffer, value.getBytes());
   }
   
   context.write(key, new Text(new String(buffer)));
   
  }
}