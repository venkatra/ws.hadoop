package ca.effpro.learn.hadoop.mr.format.xls;

import java.io.IOException;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import ca.effpro.learn.hadoop.mr.format.zip.ZipFileEntriesToContentMapper;

public class ExcelSheetRecordMapper extends
		Mapper<Text, BytesWritable, Text, Text> {
	private static final Log logger = LogFactory
			.getLog(ExcelSheetRecordMapper.class);

	private Text outKey = new Text();
	private Text outValue = new Text();
	private org.apache.hadoop.conf.Configuration conf;

	private String fromPreviousRow = "";

	public void map(Text key, BytesWritable value,
			Mapper<Text, BytesWritable, Text, Text>.Context context)
			throws IOException, InterruptedException {

		String row = fromPreviousRow + new String(value.getBytes());
		int idx = row.lastIndexOf('\n');

		fromPreviousRow = row.substring(idx);
		outValue.set(row.substring(0, idx));

		context.write(key, outValue);
	}
}